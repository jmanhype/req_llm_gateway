name: Self-Improvement Report

on:
  schedule:
    # Run every Monday at 10:00 UTC
    - cron: '0 10 * * 1'
  workflow_dispatch:

permissions:
  contents: write
  issues: write
  pull-requests: read

jobs:
  generate_metrics:
    name: Generate Quality Metrics
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0  # Full history for trend analysis

      - name: Set up Elixir
        uses: erlef/setup-beam@v1
        with:
          elixir-version: "1.16.x"
          otp-version: "26.x"

      - name: Install dependencies
        run: mix deps.get

      - name: Collect code metrics
        run: |
          cat > metrics_report.md << 'EOF'
          ## Code Metrics Report

          ### Repository Statistics

          EOF

          # Basic statistics
          echo "#### Lines of Code" >> metrics_report.md
          total_elixir=$(find lib -name "*.ex" | xargs wc -l | tail -1 | awk '{print $1}')
          total_tests=$(find test -name "*.exs" | xargs wc -l | tail -1 | awk '{print $1}')
          echo "- Production code: $total_elixir lines" >> metrics_report.md
          echo "- Test code: $total_tests lines" >> metrics_report.md
          test_ratio=$(echo "scale=2; $total_tests / $total_elixir" | bc)
          echo "- Test-to-code ratio: $test_ratio" >> metrics_report.md

          echo "" >> metrics_report.md
          echo "#### Module Counts" >> metrics_report.md
          module_count=$(find lib -name "*.ex" | wc -l)
          test_count=$(find test -name "*.exs" | wc -l)
          echo "- Modules: $module_count" >> metrics_report.md
          echo "- Test files: $test_count" >> metrics_report.md

          echo "" >> metrics_report.md
          echo "#### Commit Activity (Last 30 Days)" >> metrics_report.md
          commit_count=$(git log --since="30 days ago" --oneline | wc -l)
          echo "- Total commits: $commit_count" >> metrics_report.md
          contributors=$(git log --since="30 days ago" --format="%an" | sort -u | wc -l)
          echo "- Active contributors: $contributors" >> metrics_report.md

      - name: Run test coverage
        run: |
          mix coveralls.json || true

          cat >> metrics_report.md << 'EOF'

          ### Test Coverage

          EOF

          if [ -f cover/excoveralls.json ]; then
            # Extract coverage percentage (this is a simplified version)
            echo "Coverage report generated" >> metrics_report.md
          else
            echo "Coverage data not available" >> metrics_report.md
          fi

      - name: Run quality checks
        continue-on-error: true
        run: |
          mix credo --strict --format json > credo_output.json || true

          cat >> metrics_report.md << 'EOF'

          ### Code Quality

          EOF

          if [ -f credo_output.json ]; then
            echo "Credo analysis completed" >> metrics_report.md
          fi

      - name: Analyze code churn
        run: |
          cat >> metrics_report.md << 'EOF'

          ### Code Churn Analysis

          #### Most Changed Files (Last 30 Days)

          EOF

          git log --since="30 days ago" --name-only --pretty=format: | \
            sort | uniq -c | sort -rn | head -10 | \
            awk '{print "- " $2 " (" $1 " changes)"}' >> metrics_report.md

      - name: Store metrics
        run: |
          mkdir -p .metrics
          DATE=$(date +%Y-%m-%d)
          cp metrics_report.md .metrics/metrics_$DATE.md

      - name: Upload metrics
        uses: actions/upload-artifact@v3
        with:
          name: code-metrics
          path: metrics_report.md
          retention-days: 90

  analyze_trends:
    name: Analyze Quality Trends
    runs-on: ubuntu-latest
    needs: generate_metrics

    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Download metrics
        uses: actions/download-artifact@v3
        with:
          name: code-metrics

      - name: Analyze trends
        run: |
          cat > trends_report.md << 'EOF'
          ## Quality Trends Analysis

          ### Historical Comparison

          This section compares current metrics with historical data to identify trends.

          EOF

          # Check if we have historical data
          if [ -d .metrics ]; then
            echo "#### Previous Reports Available" >> trends_report.md
            ls -lt .metrics/ | head -5 >> trends_report.md || echo "No previous reports" >> trends_report.md
          else
            echo "No historical data available yet. Trends will be available after multiple runs." >> trends_report.md
          fi

          cat >> trends_report.md << 'EOF'

          ### Trend Indicators

          #### Code Growth
          - Track lines of code over time
          - Monitor complexity increases
          - Identify areas of rapid change

          #### Test Coverage Trends
          - Coverage percentage over time
          - New untested code
          - Test maintenance

          #### Quality Score Trends
          - Credo issues over time
          - Documentation coverage
          - Type specification coverage

          #### Development Velocity
          - Commits per week
          - PRs merged per week
          - Issue resolution time

          ### Improvement Indicators

          **Positive Trends** ğŸŸ¢
          - Increasing test coverage
          - Decreasing Credo issues
          - Improving documentation coverage
          - Consistent commit activity
          - Faster issue resolution

          **Areas Needing Attention** ğŸ”´
          - Decreasing test coverage
          - Increasing complexity without tests
          - Growing technical debt
          - Slowing development velocity
          - Accumulating TODO comments
          EOF

      - name: Upload trends report
        uses: actions/upload-artifact@v3
        with:
          name: trends-report
          path: trends_report.md
          retention-days: 90

  generate_improvement_plan:
    name: Generate Improvement Plan
    runs-on: ubuntu-latest
    needs: [generate_metrics, analyze_trends]

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Download all reports
        uses: actions/download-artifact@v3

      - name: Create comprehensive improvement plan
        run: |
          cat > improvement_plan.md << 'EOF'
          # ğŸš€ Self-Improvement Action Plan

          ## Executive Summary

          This automated analysis identifies improvement opportunities across:
          - Code quality and maintainability
          - Test coverage and quality
          - Documentation completeness
          - Security and dependencies
          - Development practices

          ---

          ## Priority Matrix

          ### High Priority (Address This Week)
          - [ ] Security vulnerabilities (if any)
          - [ ] Test failures or instability
          - [ ] Critical bugs in main branch
          - [ ] Outdated dependencies with known issues

          ### Medium Priority (Address This Sprint)
          - [ ] Low test coverage areas
          - [ ] Missing documentation
          - [ ] Code quality issues from Credo
          - [ ] Performance bottlenecks

          ### Low Priority (Continuous Improvement)
          - [ ] Code style consistency
          - [ ] Refactoring opportunities
          - [ ] Enhanced documentation
          - [ ] Development tooling improvements

          ---

          ## Automated Improvement Suggestions

          ### 1. Testing Improvements
          **Goal:** Achieve and maintain >85% test coverage

          **Actions:**
          - Add tests for modules without test files
          - Increase coverage for under-tested modules
          - Add property-based tests for complex logic
          - Implement integration tests for critical paths

          **Automation:**
          - Coverage reports on every PR
          - Automated alerts for coverage drops
          - Test template generation

          ### 2. Code Quality Enhancements
          **Goal:** Zero Credo warnings in strict mode

          **Actions:**
          - Address existing Credo issues
          - Add missing type specifications
          - Improve function documentation
          - Refactor complex functions

          **Automation:**
          - Pre-commit hooks for formatting
          - Automated code review comments
          - Style guide enforcement

          ### 3. Documentation Completeness
          **Goal:** >95% module documentation coverage

          **Actions:**
          - Add @moduledoc to all modules
          - Document all public functions
          - Add usage examples
          - Create architecture documentation

          **Automation:**
          - Documentation generation on merge
          - Coverage tracking
          - Automated link checking

          ### 4. Security Posture
          **Goal:** Zero known vulnerabilities

          **Actions:**
          - Update vulnerable dependencies
          - Regular security audits
          - Code security review
          - Secret scanning

          **Automation:**
          - Daily dependency audits
          - Automated security PRs
          - Vulnerability notifications

          ### 5. Performance Optimization
          **Goal:** Maintain sub-100ms response times

          **Actions:**
          - Profile critical paths
          - Optimize database queries
          - Implement caching strategies
          - Load testing

          **Automation:**
          - Performance regression testing
          - Automated profiling
          - Benchmark tracking

          ---

          ## Self-Improvement Metrics

          ### Current Status
          - Code quality score: Measuring...
          - Test coverage: Measuring...
          - Documentation coverage: Measuring...
          - Security status: Measuring...

          ### Target Goals (Next Quarter)
          - Code quality score: >90%
          - Test coverage: >85%
          - Documentation coverage: >95%
          - Security vulnerabilities: 0

          ---

          ## Continuous Improvement Process

          ### Weekly Activities
          1. Review automated quality reports
          2. Address high-priority issues
          3. Merge dependabot PRs
          4. Update documentation

          ### Monthly Activities
          1. Review quality trends
          2. Update improvement plan
          3. Refactor technical debt
          4. Knowledge sharing session

          ### Quarterly Activities
          1. Major dependency updates
          2. Architecture review
          3. Performance audit
          4. Security assessment

          ---

          ## Automation Tools in Place

          âœ… **CI/CD Pipeline**
          - Automated testing on all PRs
          - Code quality checks
          - Coverage reporting
          - Security scanning

          âœ… **Code Review Automation**
          - AI-powered code review
          - Pattern analysis
          - Complexity detection

          âœ… **Quality Improvement**
          - Weekly quality reports
          - Automated issue creation
          - Improvement suggestions

          âœ… **Security Monitoring**
          - Daily dependency audits
          - Vulnerability scanning
          - License compliance

          âœ… **Documentation**
          - Auto-generated API docs
          - Coverage tracking
          - Link validation

          ---

          ## Next Steps

          1. **Review this report** with the development team
          2. **Prioritize improvements** based on business impact
          3. **Create tasks** for high-priority items
          4. **Schedule** improvement work in sprints
          5. **Monitor progress** through automated metrics

          ---

          ## Success Metrics

          Track these metrics to measure improvement:

          | Metric | Current | Target | Trend |
          |--------|---------|--------|-------|
          | Test Coverage | TBD | >85% | ğŸ“Š |
          | Code Quality | TBD | >90% | ğŸ“Š |
          | Documentation | TBD | >95% | ğŸ“Š |
          | Security Issues | TBD | 0 | ğŸ“Š |
          | Build Time | TBD | <5min | ğŸ“Š |
          | Dependencies | TBD | All current | ğŸ“Š |

          ---

          **Report Generated:** $(date)
          **Next Review:** Next Monday
          EOF

      - name: Create improvement issue
        uses: actions/github-script@v7
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            const fs = require('fs');
            const improvementPlan = fs.readFileSync('improvement_plan.md', 'utf8');
            const date = new Date().toISOString().split('T')[0];

            // Check for existing open improvement report
            const issues = await github.rest.issues.listForRepo({
              owner: context.repo.owner,
              repo: context.repo.repo,
              state: 'open',
              labels: 'self-improvement',
              sort: 'created',
              direction: 'desc',
              per_page: 1
            });

            if (issues.data.length > 0) {
              // Update existing issue with new report
              await github.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: issues.data[0].number,
                body: `## Weekly Update - ${date}\n\n${improvementPlan}`
              });
              console.log(`Updated existing issue #${issues.data[0].number}`);
            } else {
              // Create new issue
              const issue = await github.rest.issues.create({
                owner: context.repo.owner,
                repo: context.repo.repo,
                title: `ğŸ¤– Self-Improvement Report - ${date}`,
                body: improvementPlan,
                labels: ['self-improvement', 'automated', 'quality']
              });
              console.log(`Created new issue #${issue.data.number}`);
            }

      - name: Generate summary report
        run: |
          cat > summary.md << 'EOF'
          # Weekly Self-Improvement Summary

          ## Reports Generated
          - âœ… Code Metrics
          - âœ… Quality Trends
          - âœ… Improvement Plan

          ## Key Actions
          1. Review the improvement plan issue
          2. Address high-priority items
          3. Track progress on metrics
          4. Celebrate improvements!

          ## Automation Status
          All self-improvement workflows running successfully.

          Next report: Next Monday at 10:00 UTC
          EOF

      - name: Upload all reports
        uses: actions/upload-artifact@v3
        with:
          name: self-improvement-complete
          path: |
            improvement_plan.md
            summary.md
          retention-days: 90
